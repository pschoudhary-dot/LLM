
  * ## [ deepseek-r1 DeepSeek's first-generation of reasoning models with comparable performance to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on Llama and Qwen. 1.5b 7b 8b 14b 32b 70b 671b 22.6M Pulls 29 Tags Updated  3 weeks ago ](https://ollama.com/</library/deepseek-r1>)
  * ## [ llama3.3 New state of the art 70B model. Llama 3.3 70B offers similar performance compared to the Llama 3.1 405B model. tools 70b 1.4M Pulls 14 Tags Updated  2 months ago ](https://ollama.com/</library/llama3.3>)
  * ## [ phi4 Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft. 14b 861.2K Pulls 5 Tags Updated  7 weeks ago ](https://ollama.com/</library/phi4>)
  * ## [ llama3.2 Meta's Llama 3.2 goes small with 1B and 3B models.  tools 1b 3b 9.8M Pulls 63 Tags Updated  5 months ago ](https://ollama.com/</library/llama3.2>)
  * ## [ llama3.1 Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes. tools 8b 70b 405b 25.7M Pulls 93 Tags Updated  3 months ago ](https://ollama.com/</library/llama3.1>)
  * ## [ nomic-embed-text A high-performing open embedding model with a large token context window. embedding 17.9M Pulls 3 Tags Updated  12 months ago ](https://ollama.com/</library/nomic-embed-text>)
  * ## [ mistral The 7B model released by Mistral AI, updated to version 0.3. tools 7b 9.8M Pulls 84 Tags Updated  7 months ago ](https://ollama.com/</library/mistral>)
  * ## [ llama3 Meta Llama 3: The most capable openly available LLM to date 8b 70b 7.6M Pulls 68 Tags Updated  9 months ago ](https://ollama.com/</library/llama3>)
  * ## [ qwen2.5 Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support.  tools 0.5b 1.5b 3b 7b 14b 32b 72b 4.9M Pulls 133 Tags Updated  5 months ago ](https://ollama.com/</library/qwen2.5>)
  * ## [ qwen Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from 0.5B to 110B parameters 0.5b 1.8b 4b 7b 14b 32b 72b 110b 4.5M Pulls 379 Tags Updated  10 months ago ](https://ollama.com/</library/qwen>)
  * ## [ qwen2.5-coder The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing. tools 0.5b 1.5b 3b 7b 14b 32b 4.4M Pulls 196 Tags Updated  3 months ago ](https://ollama.com/</library/qwen2.5-coder>)
  * ## [ gemma Gemma is a family of lightweight, state-of-the-art open models built by Google DeepMind. Updated to version 1.1 2b 7b 4.4M Pulls 102 Tags Updated  10 months ago ](https://ollama.com/</library/gemma>)
  * ## [ qwen2 Qwen2 is a new series of large language models from Alibaba group tools 0.5b 1.5b 7b 72b 4.1M Pulls 97 Tags Updated  5 months ago ](https://ollama.com/</library/qwen2>)
  * ## [ llava üåã LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6. vision 7b 13b 34b 3.7M Pulls 98 Tags Updated  13 months ago ](https://ollama.com/</library/llava>)
  * ## [ gemma2 Google Gemma 2 is a high-performing and efficient model available in three sizes: 2B, 9B, and 27B. 2b 9b 27b 3.1M Pulls 94 Tags Updated  7 months ago ](https://ollama.com/</library/gemma2>)
  * ## [ llama2 Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters. 7b 13b 70b 3M Pulls 102 Tags Updated  14 months ago ](https://ollama.com/</library/llama2>)
  * ## [ phi3 Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft. 3.8b 14b 2.9M Pulls 72 Tags Updated  7 months ago ](https://ollama.com/</library/phi3>)
  * ## [ codellama A large language model that can use text prompts to generate and discuss code. 7b 13b 34b 70b 1.8M Pulls 199 Tags Updated  7 months ago ](https://ollama.com/</library/codellama>)
  * ## [ mxbai-embed-large State-of-the-art large embedding model from mixedbread.ai embedding 335m 1.7M Pulls 4 Tags Updated  10 months ago ](https://ollama.com/</library/mxbai-embed-large>)
  * ## [ llama3.2-vision Llama 3.2 Vision is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes. vision 11b 90b 1.4M Pulls 9 Tags Updated  3 months ago ](https://ollama.com/</library/llama3.2-vision>)
  * ## [ tinyllama The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens. 1.1b 1.3M Pulls 36 Tags Updated  14 months ago ](https://ollama.com/</library/tinyllama>)
  * ## [ mistral-nemo A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA. tools 12b 1.3M Pulls 17 Tags Updated  7 months ago ](https://ollama.com/</library/mistral-nemo>)
  * ## [ starcoder2 StarCoder2 is the next generation of transparently trained open code LLMs that comes in three sizes: 3B, 7B and 15B parameters.  3b 7b 15b 893.1K Pulls 67 Tags Updated  5 months ago ](https://ollama.com/</library/starcoder2>)
  * ## [ deepseek-v3 A strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. 671b 707K Pulls 5 Tags Updated  7 weeks ago ](https://ollama.com/</library/deepseek-v3>)
  * ## [ deepseek-coder-v2 An open-source Mixture-of-Experts code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks. 16b 236b 702.9K Pulls 64 Tags Updated  5 months ago ](https://ollama.com/</library/deepseek-coder-v2>)
  * ## [ snowflake-arctic-embed A suite of text embedding models by Snowflake, optimized for performance. embedding 22m 33m 110m 137m 335m 695K Pulls 16 Tags Updated  10 months ago ](https://ollama.com/</library/snowflake-arctic-embed>)
  * ## [ llama2-uncensored Uncensored Llama 2 model by George Sung and Jarrad Hope. 7b 70b 631.8K Pulls 34 Tags Updated  16 months ago ](https://ollama.com/</library/llama2-uncensored>)
  * ## [ deepseek-coder DeepSeek Coder is a capable coding model trained on two trillion code and natural language tokens. 1.3b 6.7b 33b 589.2K Pulls 102 Tags Updated  14 months ago ](https://ollama.com/</library/deepseek-coder>)
  * ## [ mixtral A set of Mixture of Experts (MoE) model with open weights by Mistral AI in 8x7b and 8x22b parameter sizes. tools 8x7b 8x22b 576.5K Pulls 70 Tags Updated  2 months ago ](https://ollama.com/</library/mixtral>)
  * ## [ dolphin-mixtral Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of experts models that excels at coding tasks. Created by Eric Hartford. 8x7b 8x22b 517.9K Pulls 70 Tags Updated  2 months ago ](https://ollama.com/</library/dolphin-mixtral>)
  * ## [ codegemma CodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following. 2b 7b 514K Pulls 85 Tags Updated  7 months ago ](https://ollama.com/</library/codegemma>)
  * ## [ openthinker A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1. 7b 32b 506.1K Pulls 9 Tags Updated  2 weeks ago ](https://ollama.com/</library/openthinker>)
  * ## [ bge-m3 BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity. embedding 567m 498.2K Pulls 3 Tags Updated  6 months ago ](https://ollama.com/</library/bge-m3>)
  * ## [ phi Phi-2: a 2.7B language model by Microsoft Research that demonstrates outstanding reasoning and language understanding capabilities. 2.7b 494K Pulls 18 Tags Updated  14 months ago ](https://ollama.com/</library/phi>)
  * ## [ minicpm-v A series of multimodal LLMs (MLLMs) designed for vision-language understanding. vision 8b 433.8K Pulls 17 Tags Updated  3 months ago ](https://ollama.com/</library/minicpm-v>)
  * ## [ llava-llama3 A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several benchmarks. vision 8b 395.5K Pulls 4 Tags Updated  10 months ago ](https://ollama.com/</library/llava-llama3>)
  * ## [ wizardlm2 State of the art large language model from Microsoft AI with improved performance on complex chat, multilingual, reasoning and agent use cases. 7b 8x22b 355.6K Pulls 22 Tags Updated  10 months ago ](https://ollama.com/</library/wizardlm2>)
  * ## [ dolphin-mistral The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8. 7b 323.4K Pulls 120 Tags Updated  11 months ago ](https://ollama.com/</library/dolphin-mistral>)
  * ## [ smollm2 SmolLM2 is a family of compact language models available in three size: 135M, 360M, and 1.7B parameters. tools 135m 360m 1.7b 319.5K Pulls 49 Tags Updated  4 months ago ](https://ollama.com/</library/smollm2>)
  * ## [ all-minilm Embedding models on very large sentence level datasets. embedding 22m 33m 304.6K Pulls 10 Tags Updated  10 months ago ](https://ollama.com/</library/all-minilm>)
  * ## [ dolphin-llama3 Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on Llama 3 that has a variety of instruction, conversational, and coding skills. 8b 70b 289.5K Pulls 53 Tags Updated  9 months ago ](https://ollama.com/</library/dolphin-llama3>)
  * ## [ dolphin3 Dolphin 3.0 Llama 3.1 8B üê¨ is the next generation of the Dolphin series of instruct-tuned models designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases. 8b 287K Pulls 5 Tags Updated  8 weeks ago ](https://ollama.com/</library/dolphin3>)
  * ## [ command-r Command R is a Large Language Model optimized for conversational interaction and long context tasks. tools 35b 281.7K Pulls 32 Tags Updated  6 months ago ](https://ollama.com/</library/command-r>)
  * ## [ orca-mini A general-purpose model ranging from 3 billion parameters to 70 billion, suitable for entry-level hardware. 3b 7b 13b 70b 276.1K Pulls 119 Tags Updated  16 months ago ](https://ollama.com/</library/orca-mini>)
  * ## [ yi Yi 1.5 is a high-performing, bilingual language model. 6b 9b 34b 266.3K Pulls 174 Tags Updated  9 months ago ](https://ollama.com/</library/yi>)
  * ## [ hermes3 Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous Research tools 3b 8b 70b 405b 261.5K Pulls 65 Tags Updated  2 months ago ](https://ollama.com/</library/hermes3>)
  * ## [ olmo2 OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. These models are on par with or better than equivalently sized fully open models, and competitive with open-weight models such as Llama 3.1 on English academic benchmarks. 7b 13b 255.3K Pulls 9 Tags Updated  7 weeks ago ](https://ollama.com/</library/olmo2>)
  * ## [ phi3.5 A lightweight AI model with 3.8 billion parameters with performance overtaking similarly and larger sized models. 3.8b 246.5K Pulls 17 Tags Updated  5 months ago ](https://ollama.com/</library/phi3.5>)
  * ## [ mistral-small Mistral Small 3 sets a new benchmark in the ‚Äúsmall‚Äù Large Language Models category below 70B. tools 22b 24b 241K Pulls 21 Tags Updated  4 weeks ago ](https://ollama.com/</library/mistral-small>)
  * ## [ zephyr Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models that are trained to act as helpful assistants. 7b 141b 237.5K Pulls 40 Tags Updated  10 months ago ](https://ollama.com/</library/zephyr>)
  * ## [ codestral Codestral is Mistral AI‚Äôs first-ever code model designed for code generation tasks. 22b 223.8K Pulls 17 Tags Updated  6 months ago ](https://ollama.com/</library/codestral>)
  * ## [ granite-code A family of open foundation models by IBM for Code Intelligence 3b 8b 20b 34b 189.6K Pulls 162 Tags Updated  6 months ago ](https://ollama.com/</library/granite-code>)
  * ## [ starcoder StarCoder is a code generation model trained on 80+ programming languages. 1b 3b 7b 15b 186.6K Pulls 100 Tags Updated  16 months ago ](https://ollama.com/</library/starcoder>)
  * ## [ smollm ü™ê A family of small models with 135M, 360M, and 1.7B parameters, trained on a new high-quality dataset. 135m 360m 1.7b 183.1K Pulls 94 Tags Updated  6 months ago ](https://ollama.com/</library/smollm>)
  * ## [ wizard-vicuna-uncensored Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on Llama 2 uncensored by Eric Hartford. 7b 13b 30b 181.9K Pulls 49 Tags Updated  16 months ago ](https://ollama.com/</library/wizard-vicuna-uncensored>)
  * ## [ vicuna General use chat model based on Llama and Llama 2 with 2K to 16K context sizes. 7b 13b 33b 175.5K Pulls 111 Tags Updated  16 months ago ](https://ollama.com/</library/vicuna>)
  * ## [ mistral-openorca Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset. 7b 166.6K Pulls 17 Tags Updated  16 months ago ](https://ollama.com/</library/mistral-openorca>)
  * ## [ qwq QwQ is an experimental research model focused on advancing AI reasoning capabilities. tools 32b 164.2K Pulls 5 Tags Updated  3 months ago ](https://ollama.com/</library/qwq>)
  * ## [ llama2-chinese Llama 2 based model fine tuned to improve Chinese dialogue ability. 7b 13b 149.3K Pulls 35 Tags Updated  16 months ago ](https://ollama.com/</library/llama2-chinese>)
  * ## [ openchat A family of open-source models trained on a wide variety of data, surpassing ChatGPT on various benchmarks. Updated to version 3.5-0106. 7b 144.3K Pulls 50 Tags Updated  13 months ago ](https://ollama.com/</library/openchat>)
  * ## [ codegeex4 A versatile model for AI software development scenarios, including code completion. 9b 138.3K Pulls 17 Tags Updated  7 months ago ](https://ollama.com/</library/codegeex4>)
  * ## [ aya Aya 23, released by Cohere, is a new family of state-of-the-art, multilingual models that support 23 languages.  8b 35b 135.1K Pulls 33 Tags Updated  9 months ago ](https://ollama.com/</library/aya>)
  * ## [ codeqwen CodeQwen1.5 is a large language model pretrained on a large amount of code data. 7b 130.8K Pulls 30 Tags Updated  8 months ago ](https://ollama.com/</library/codeqwen>)
  * ## [ deepseek-llm An advanced language model crafted with 2 trillion bilingual tokens. 7b 67b 130.3K Pulls 64 Tags Updated  14 months ago ](https://ollama.com/</library/deepseek-llm>)
  * ## [ deepseek-v2 A strong, economical, and efficient Mixture-of-Experts language model. 16b 236b 125K Pulls 34 Tags Updated  8 months ago ](https://ollama.com/</library/deepseek-v2>)
  * ## [ mistral-large Mistral Large 2 is Mistral's new flagship model that is significantly more capable in code generation, mathematics, and reasoning with 128k context window and support for dozens of languages. tools 123b 123.8K Pulls 32 Tags Updated  3 months ago ](https://ollama.com/</library/mistral-large>)
  * ## [ glm4 A strong multi-lingual general language model with competitive performance to Llama 3. 9b 122.1K Pulls 32 Tags Updated  7 months ago ](https://ollama.com/</library/glm4>)
  * ## [ nous-hermes2 The powerful family of models by Nous Research that excels at scientific discussion and coding tasks. 10.7b 34b 121.5K Pulls 33 Tags Updated  14 months ago ](https://ollama.com/</library/nous-hermes2>)
  * ## [ stable-code Stable Code 3B is a coding model with instruct and code completion variants on par with models such as Code Llama 7B that are 2.5x larger. 3b 121.2K Pulls 36 Tags Updated  11 months ago ](https://ollama.com/</library/stable-code>)
  * ## [ openhermes OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully open datasets. 120.9K Pulls 35 Tags Updated  14 months ago ](https://ollama.com/</library/openhermes>)
  * ## [ qwen2-math Qwen2 Math is a series of specialized math language models built upon the Qwen2 LLMs, which significantly outperforms the mathematical capabilities of open-source models and even closed-source models (e.g., GPT4o). 1.5b 7b 72b 119.5K Pulls 52 Tags Updated  6 months ago ](https://ollama.com/</library/qwen2-math>)
  * ## [ tinydolphin An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset by Eric Hartford and based on TinyLlama. 1.1b 119.4K Pulls 18 Tags Updated  13 months ago ](https://ollama.com/</library/tinydolphin>)
  * ## [ command-r-plus Command R+ is a powerful, scalable large language model purpose-built to excel at real-world enterprise use cases. tools 104b 119K Pulls 21 Tags Updated  6 months ago ](https://ollama.com/</library/command-r-plus>)
  * ## [ wizardcoder State-of-the-art code generation model 33b 116.6K Pulls 67 Tags Updated  14 months ago ](https://ollama.com/</library/wizardcoder>)
  * ## [ moondream moondream2 is a small vision language model designed to run efficiently on edge devices. vision 1.8b 111.5K Pulls 18 Tags Updated  10 months ago ](https://ollama.com/</library/moondream>)
  * ## [ bakllava BakLLaVA is a multimodal model consisting of the Mistral 7B base model augmented with the LLaVA architecture. vision 7b 108.8K Pulls 17 Tags Updated  14 months ago ](https://ollama.com/</library/bakllava>)
  * ## [ stablelm2 Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch. 1.6b 12b 107.4K Pulls 84 Tags Updated  10 months ago ](https://ollama.com/</library/stablelm2>)
  * ## [ neural-chat A fine-tuned model based on Mistral with good coverage of domain and language. 7b 103.8K Pulls 50 Tags Updated  14 months ago ](https://ollama.com/</library/neural-chat>)
  * ## [ reflection A high-performing model trained with a new technique called Reflection-tuning that teaches a LLM to detect mistakes in its reasoning and correct course. 70b 103.1K Pulls 17 Tags Updated  5 months ago ](https://ollama.com/</library/reflection>)
  * ## [ wizard-math Model focused on math and logic problems 7b 13b 70b 100.7K Pulls 64 Tags Updated  14 months ago ](https://ollama.com/</library/wizard-math>)
  * ## [ llama3-gradient This model extends LLama-3 8B's context length from 8k to over 1m tokens. 8b 70b 97.6K Pulls 35 Tags Updated  10 months ago ](https://ollama.com/</library/llama3-gradient>)
  * ## [ llama3-chatqa A model from NVIDIA based on Llama 3 that excels at conversational question answering (QA) and retrieval-augmented generation (RAG). 8b 70b 96K Pulls 35 Tags Updated  9 months ago ](https://ollama.com/</library/llama3-chatqa>)
  * ## [ sqlcoder SQLCoder is a code completion model fined-tuned on StarCoder for SQL generation tasks 7b 15b 92.3K Pulls 48 Tags Updated  13 months ago ](https://ollama.com/</library/sqlcoder>)
  * ## [ bge-large Embedding model from BAAI mapping texts to vectors. embedding 335m 86.3K Pulls 3 Tags Updated  6 months ago ](https://ollama.com/</library/bge-large>)
  * ## [ xwinlm Conversational model based on Llama 2 that performs competitively on various benchmarks. 7b 13b 84.1K Pulls 80 Tags Updated  16 months ago ](https://ollama.com/</library/xwinlm>)
  * ## [ dolphincoder A 7B and 15B uncensored variant of the Dolphin model family that excels at coding, based on StarCoder2. 7b 15b 83.5K Pulls 35 Tags Updated  10 months ago ](https://ollama.com/</library/dolphincoder>)
  * ## [ nous-hermes General use models based on Llama and Llama 2 from Nous Research. 7b 13b 82K Pulls 63 Tags Updated  16 months ago ](https://ollama.com/</library/nous-hermes>)
  * ## [ phind-codellama Code generation model based on Code Llama. 34b 81.2K Pulls 49 Tags Updated  14 months ago ](https://ollama.com/</library/phind-codellama>)
  * ## [ llava-phi3 A new small LLaVA model fine-tuned from Phi 3 Mini. vision 3.8b 79.9K Pulls 4 Tags Updated  10 months ago ](https://ollama.com/</library/llava-phi3>)
  * ## [ granite3.1-dense The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 trillion tokens of data, demonstrated significant improvements over their predecessors in performance and speed in IBM‚Äôs initial testing. tools 2b 8b 79.3K Pulls 33 Tags Updated  6 weeks ago ](https://ollama.com/</library/granite3.1-dense>)
  * ## [ yarn-llama2 An extension of Llama 2 that supports a context of up to 128k tokens. 7b 13b 78.6K Pulls 67 Tags Updated  16 months ago ](https://ollama.com/</library/yarn-llama2>)
  * ## [ solar A compact, yet powerful 10.7B large language model designed for single-turn conversation. 10.7b 78.6K Pulls 32 Tags Updated  14 months ago ](https://ollama.com/</library/solar>)
  * ## [ samantha-mistral A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral. 7b 78.4K Pulls 49 Tags Updated  16 months ago ](https://ollama.com/</library/samantha-mistral>)
  * ## [ starling-lm Starling is a large language model trained by reinforcement learning from AI feedback focused on improving chatbot helpfulness. 7b 77.2K Pulls 36 Tags Updated  11 months ago ](https://ollama.com/</library/starling-lm>)
  * ## [ athene-v2 Athene-V2 is a 72B parameter model which excels at code completion, mathematics, and log extraction tasks. tools 72b 76.4K Pulls 17 Tags Updated  3 months ago ](https://ollama.com/</library/athene-v2>)
  * ## [ yi-coder Yi-Coder is a series of open-source code language models that delivers state-of-the-art coding performance with fewer than 10 billion parameters. 1.5b 9b 76.1K Pulls 67 Tags Updated  5 months ago ](https://ollama.com/</library/yi-coder>)
  * ## [ wizardlm General use model based on Llama 2. 75.7K Pulls 73 Tags Updated  16 months ago ](https://ollama.com/</library/wizardlm>)
  * ## [ internlm2 InternLM2.5 is a 7B parameter model tailored for practical scenarios with outstanding reasoning capability. 1m 1.8b 7b 20b 73.2K Pulls 65 Tags Updated  6 months ago ](https://ollama.com/</library/internlm2>)
  * ## [ falcon A large language model built by the Technology Innovation Institute (TII) for use in summarization, text generation, and chat bots. 7b 40b 180b 69.6K Pulls 38 Tags Updated  16 months ago ](https://ollama.com/</library/falcon>)
  * ## [ nemotron-mini A commercial-friendly small language model by NVIDIA optimized for roleplay, RAG QA, and function calling. tools 4b 68.5K Pulls 17 Tags Updated  5 months ago ](https://ollama.com/</library/nemotron-mini>)
  * ## [ nemotron Llama-3.1-Nemotron-70B-Instruct is a large language model customized by NVIDIA to improve the helpfulness of LLM generated responses to user queries. tools 70b 66.3K Pulls 17 Tags Updated  4 months ago ](https://ollama.com/</library/nemotron>)
  * ## [ dolphin-phi 2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language model by Microsoft Research. 2.7b 64.8K Pulls 15 Tags Updated  14 months ago ](https://ollama.com/</library/dolphin-phi>)
  * ## [ orca2 Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta's Llama 2 models. The model is designed to excel particularly in reasoning. 7b 13b 63.1K Pulls 33 Tags Updated  15 months ago ](https://ollama.com/</library/orca2>)
  * ## [ deepscaler A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the performance of OpenAI‚Äôs o1-preview with just 1.5B parameters on popular math evaluations. 1.5b 63.1K Pulls 5 Tags Updated  2 weeks ago ](https://ollama.com/</library/deepscaler>)
  * ## [ wizardlm-uncensored Uncensored version of Wizard LM model  13b 60.2K Pulls 18 Tags Updated  16 months ago ](https://ollama.com/</library/wizardlm-uncensored>)
  * ## [ stable-beluga Llama 2 based model fine tuned on an Orca-style dataset. Originally called Free Willy. 7b 13b 70b 58.8K Pulls 49 Tags Updated  16 months ago ](https://ollama.com/</library/stable-beluga>)
  * ## [ granite3-dense The IBM Granite 2B and 8B models are designed to support tool-based use cases and support for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing. tools 2b 8b 56.6K Pulls 33 Tags Updated  3 months ago ](https://ollama.com/</library/granite3-dense>)
  * ## [ llama3-groq-tool-use A series of models from Groq that represent a significant advancement in open-source AI capabilities for tool use/function calling. tools 8b 70b 54.9K Pulls 33 Tags Updated  7 months ago ](https://ollama.com/</library/llama3-groq-tool-use>)
  * ## [ paraphrase-multilingual Sentence-transformers model that can be used for tasks like clustering or semantic search. embedding 278m 51.9K Pulls 3 Tags Updated  6 months ago ](https://ollama.com/</library/paraphrase-multilingual>)
  * ## [ deepseek-v2.5 An upgraded version of DeekSeek-V2 that integrates the general and coding abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct. 236b 49.3K Pulls 7 Tags Updated  5 months ago ](https://ollama.com/</library/deepseek-v2.5>)
  * ## [ medllama2 Fine-tuned Llama 2 model to answer medical questions based on an open source medical dataset.  7b 47.1K Pulls 17 Tags Updated  16 months ago ](https://ollama.com/</library/medllama2>)
  * ## [ meditron Open-source medical large language model adapted from Llama 2 to the medical domain. 7b 70b 46.9K Pulls 22 Tags Updated  15 months ago ](https://ollama.com/</library/meditron>)
  * ## [ smallthinker A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model. 3b 46.6K Pulls 5 Tags Updated  2 months ago ](https://ollama.com/</library/smallthinker>)
  * ## [ llama-pro An expansion of Llama 2 that specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics. 45.5K Pulls 33 Tags Updated  14 months ago ](https://ollama.com/</library/llama-pro>)
  * ## [ aya-expanse Cohere For AI's language models trained to perform well across 23 different languages. tools 8b 32b 45.4K Pulls 33 Tags Updated  4 months ago ](https://ollama.com/</library/aya-expanse>)
  * ## [ yarn-mistral An extension of Mistral to support context windows of 64K or 128K. 7b 45K Pulls 33 Tags Updated  16 months ago ](https://ollama.com/</library/yarn-mistral>)
  * ## [ granite3-moe The IBM Granite 1B and 3B models are the first mixture of experts (MoE) Granite models from IBM designed for low latency usage. tools 1b 3b 43.6K Pulls 33 Tags Updated  3 months ago ](https://ollama.com/</library/granite3-moe>)
  * ## [ nexusraven Nexus Raven is a 13B instruction tuned model for function calling tasks.  13b 41.4K Pulls 32 Tags Updated  13 months ago ](https://ollama.com/</library/nexusraven>)
  * ## [ falcon3 A family of efficient AI models under 10B parameters performant in science, math, and coding through innovative training techniques. 1b 3b 7b 10b 40.6K Pulls 17 Tags Updated  2 months ago ](https://ollama.com/</library/falcon3>)
  * ## [ codeup Great code generation model based on Llama2. 13b 39.5K Pulls 19 Tags Updated  16 months ago ](https://ollama.com/</library/codeup>)
  * ## [ nous-hermes2-mixtral The Nous Hermes 2 model from Nous Research, now trained over Mixtral. 8x7b 38.1K Pulls 18 Tags Updated  2 months ago ](https://ollama.com/</library/nous-hermes2-mixtral>)
  * ## [ everythinglm Uncensored Llama2 based model with support for a 16K context window. 13b 38K Pulls 18 Tags Updated  14 months ago ](https://ollama.com/</library/everythinglm>)
  * ## [ shieldgemma ShieldGemma is set of instruction tuned models for evaluating the safety of text prompt input and text output responses against a set of defined safety policies. 2b 9b 27b 35.4K Pulls 49 Tags Updated  4 months ago ](https://ollama.com/</library/shieldgemma>)
  * ## [ granite3.1-moe The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) Granite models from IBM designed for low latency usage. tools 1b 3b 34.4K Pulls 33 Tags Updated  6 weeks ago ](https://ollama.com/</library/granite3.1-moe>)
  * ## [ snowflake-arctic-embed2 Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual support without sacrificing English performance or scalability. embedding 568m 34.3K Pulls 3 Tags Updated  2 months ago ](https://ollama.com/</library/snowflake-arctic-embed2>)
  * ## [ marco-o1 An open large reasoning model for real-world solutions by the Alibaba International Digital Commerce Group (AIDC-AI). 7b 32.7K Pulls 5 Tags Updated  3 months ago ](https://ollama.com/</library/marco-o1>)
  * ## [ mathstral MathŒ£tral: a 7B model designed for math reasoning and scientific discovery by Mistral AI. 7b 32.1K Pulls 17 Tags Updated  7 months ago ](https://ollama.com/</library/mathstral>)
  * ## [ falcon2 Falcon2 is an 11B parameters causal decoder-only model built by TII and trained over 5T tokens. 11b 32.1K Pulls 17 Tags Updated  9 months ago ](https://ollama.com/</library/falcon2>)
  * ## [ magicoder üé© Magicoder is a family of 7B parameter models trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets. 7b 31.9K Pulls 18 Tags Updated  15 months ago ](https://ollama.com/</library/magicoder>)
  * ## [ stablelm-zephyr A lightweight chat model allowing accurate, and responsive output without requiring high-end hardware. 3b 31.8K Pulls 17 Tags Updated  14 months ago ](https://ollama.com/</library/stablelm-zephyr>)
  * ## [ reader-lm A series of models that convert HTML content to Markdown content, which is useful for content conversion tasks. 0.5b 1.5b 31.7K Pulls 33 Tags Updated  5 months ago ](https://ollama.com/</library/reader-lm>)
  * ## [ solar-pro Solar Pro Preview: an advanced large language model (LLM) with 22 billion parameters designed to fit into a single GPU 22b 31.5K Pulls 18 Tags Updated  5 months ago ](https://ollama.com/</library/solar-pro>)
  * ## [ codebooga A high-performing code instruct model created by merging two existing code models. 34b 31.2K Pulls 16 Tags Updated  16 months ago ](https://ollama.com/</library/codebooga>)
  * ## [ duckdb-nsql 7B parameter text-to-SQL model made by MotherDuck and Numbers Station. 7b 30K Pulls 17 Tags Updated  13 months ago ](https://ollama.com/</library/duckdb-nsql>)
  * ## [ mistrallite MistralLite is a fine-tuned model based on Mistral with enhanced capabilities of processing long contexts. 7b 29.8K Pulls 17 Tags Updated  16 months ago ](https://ollama.com/</library/mistrallite>)
  * ## [ llama-guard3 Llama Guard 3 is a series of models fine-tuned for content safety classification of LLM inputs and responses. 1b 8b 29.8K Pulls 33 Tags Updated  4 months ago ](https://ollama.com/</library/llama-guard3>)
  * ## [ wizard-vicuna Wizard Vicuna is a 13B parameter model based on Llama 2 trained by MelodysDreamj. 13b 29.4K Pulls 17 Tags Updated  16 months ago ](https://ollama.com/</library/wizard-vicuna>)
  * ## [ exaone3.5 EXAONE 3.5 is a collection of instruction-tuned bilingual (English and Korean) generative models ranging from 2.4B to 32B parameters, developed and released by LG AI Research.  2.4b 7.8b 32b 27K Pulls 13 Tags Updated  2 months ago ](https://ollama.com/</library/exaone3.5>)
  * ## [ opencoder OpenCoder is an open and reproducible code LLM family which includes 1.5B and 8B models, supporting chat in English and Chinese languages. 1.5b 8b 25.3K Pulls 9 Tags Updated  3 months ago ](https://ollama.com/</library/opencoder>)
  * ## [ nuextract A 3.8B model fine-tuned on a private high-quality synthetic dataset for information extraction, based on Phi-3. 3.8b 25.2K Pulls 17 Tags Updated  7 months ago ](https://ollama.com/</library/nuextract>)
  * ## [ megadolphin MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by interleaving the model with itself. 120b 25.2K Pulls 19 Tags Updated  13 months ago ](https://ollama.com/</library/megadolphin>)
  * ## [ notux A top-performing mixture of experts model, fine-tuned with high-quality data. 8x7b 24.2K Pulls 18 Tags Updated  14 months ago ](https://ollama.com/</library/notux>)
  * ## [ open-orca-platypus2 Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. Designed for chat and code generation. 13b 23.7K Pulls 17 Tags Updated  16 months ago ](https://ollama.com/</library/open-orca-platypus2>)
  * ## [ notus A 7B chat model fine-tuned with high-quality data and based on Zephyr. 7b 23.6K Pulls 18 Tags Updated  14 months ago ](https://ollama.com/</library/notus>)
  * ## [ goliath A language model created by combining two fine-tuned Llama 2 70B models into one. 23K Pulls 16 Tags Updated  15 months ago ](https://ollama.com/</library/goliath>)
  * ## [ command-r7b The smallest model in Cohere's R series delivers top-tier speed, efficiency, and quality to build powerful AI applications on commodity GPUs and edge devices. tools 7b 22.8K Pulls 5 Tags Updated  6 weeks ago ](https://ollama.com/</library/command-r7b>)
  * ## [ bespoke-minicheck A state-of-the-art fact-checking model developed by Bespoke Labs. 7b 22.3K Pulls 17 Tags Updated  5 months ago ](https://ollama.com/</library/bespoke-minicheck>)
  * ## [ granite-embedding The IBM Granite Embedding 30M and 278M models models are text-only dense biencoder embedding models, with 30M available in English only and 278M serving multilingual use cases. embedding 30m 278m 19.2K Pulls 6 Tags Updated  2 months ago ](https://ollama.com/</library/granite-embedding>)
  * ## [ tulu3 T√ºlu 3 is a leading instruction following model family, offering fully open-source data, code, and recipes by the The Allen Institute for AI. 8b 70b 19.1K Pulls 9 Tags Updated  2 months ago ](https://ollama.com/</library/tulu3>)
  * ## [ firefunction-v2 An open weights function calling model based on Llama 3, competitive with GPT-4o function calling capabilities. tools 70b 18.8K Pulls 17 Tags Updated  7 months ago ](https://ollama.com/</library/firefunction-v2>)
  * ## [ dbrx DBRX is an open, general-purpose LLM created by Databricks. 132b 18.3K Pulls 7 Tags Updated  10 months ago ](https://ollama.com/</library/dbrx>)
  * ## [ granite3-guardian The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks in prompts and/or responses. 2b 8b 16.3K Pulls 10 Tags Updated  3 months ago ](https://ollama.com/</library/granite3-guardian>)
  * ## [ alfred A robust conversational model designed to be used for both chat and instruct use cases. 40b 15.6K Pulls 7 Tags Updated  15 months ago ](https://ollama.com/</library/alfred>)
  * ## [ r1-1776 A version of the DeepSeek-R1 model that has been post trained to provide unbiased, accurate, and factual information by Perplexity.  70b 671b 12.8K Pulls 9 Tags Updated  10 days ago ](https://ollama.com/</library/r1-1776>)
  * ## [ phi4-mini Phi-4-mini brings significant enhancements in multilingual support, reasoning, and mathematics, and now, the long-awaited function calling feature is finally supported. tools 3.8b 11.6K Pulls 5 Tags Updated  3 days ago ](https://ollama.com/</library/phi4-mini>)
  * ## [ sailor2 Sailor2 are multilingual language models made for South-East Asia. Available in 1B, 8B, and 20B parameter sizes. 1b 8b 20b 9,455 Pulls 13 Tags Updated  3 months ago ](https://ollama.com/</library/sailor2>)
  * ## [ granite3.2 Granite-3.2 is a family of long-context AI models from IBM Granite fine-tuned for thinking capabilities. tools 2b 8b 8,864 Pulls 9 Tags Updated  6 days ago ](https://ollama.com/</library/granite3.2>)
  * ## [ granite3.2-vision A compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more. vision tools 2b 5,928 Pulls 5 Tags Updated  4 days ago ](https://ollama.com/</library/granite3.2-vision>)
  * ## [ command-r7b-arabic A new state-of-the-art version of the lightweight Command R7B model that excels in advanced Arabic language capabilities for enterprises in the Middle East and Northern Africa. tools 7b 2,562 Pulls 5 Tags Updated  3 days ago ](https://ollama.com/</library/command-r7b-arabic>)
